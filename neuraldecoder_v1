import os
import tarfile
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error


def extract_electrode_data(file_path):
    with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
        content = f.readlines()

    electrode_data = []
    current_electrode = {}

    lines = iter(content)  # Convert the list to an iterator

    for line in lines:
        line = line.strip()
        if "# Electrode" in line:
            if current_electrode:
                electrode_data.append(current_electrode)
                current_electrode = {}
        elif line.startswith("#Position"):
            current_electrode["Position"] = list(map(float, next(lines).strip().split()))
        elif line.startswith("#Normal"):
            current_electrode["Normal"] = list(map(float, next(lines).strip().split()))
        elif line.startswith("#Motor Function"):
            current_electrode["Motor Function"] = int(next(lines).strip())
        elif line.startswith("#Sensory Function"):
            current_electrode["Sensory Function"] = int(next(lines).strip())
        elif line.startswith("#Visual Function"):
            current_electrode["Visual Function"] = int(next(lines).strip())
        elif line.startswith("#Values"):
            values_count = int(next(lines).strip())
            current_electrode["Values"] = [float(next(lines).strip()) for _ in range(values_count)]
    
    if current_electrode:
        electrode_data.append(current_electrode)

    return electrode_data



def extract_tarball(file_path, output_dir):
    with tarfile.open(file_path, 'r:gz') as tar:
        tar.extractall(path=output_dir)
        return tar.getnames()


def process_all_files(directory):
    all_data = []
    
    for filename in os.listdir(directory):
        if filename.endswith(".gz"):
            file_path = os.path.join(directory, filename)
            extract_dir = os.path.join(directory, filename.replace(".gz", "") + "\\")
            os.makedirs(extract_dir, exist_ok=True)
            
            extracted_files = extract_tarball(file_path, extract_dir)
            
            for ext_file in extracted_files:
                ext_file_path = os.path.join(extract_dir, ext_file)
                
                # Check if the extracted file is actually a directory
                if os.path.isdir(ext_file_path):
                    for inner_file in os.listdir(ext_file_path):
                        inner_file_path = os.path.join(ext_file_path, inner_file)
                        data = extract_electrode_data(inner_file_path)
                        all_data.extend(data)
                else:
                    data = extract_electrode_data(ext_file_path)
                    all_data.extend(data)
    
    for elec in all_data[:5]:
        print(elec)
        print("-" * 50)

    return all_data


directory_path = "C:/Users/mriga/SynologyDrive/Research/Personal/Neural Decoder/Files/Data"
all_electrode_data = process_all_files(directory_path)

# Data Preprocessing

X = [elec["Values"] for elec in all_electrode_data if "Values" in elec and "Motor Function" in elec]
y = [elec["Motor Function"] for elec in all_electrode_data if "Values" in elec and "Motor Function" in elec]

X = np.array(X)
y = np.array(y)

scaler = StandardScaler()
X = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Model Selection and Training

model = LinearRegression()
model.fit(X_train, y_train)

y_pred_train = model.predict(X_train)
y_pred_test = model.predict(X_test)

# Evaluation

mse_train = mean_squared_error(y_train, y_pred_train)
mse_test = mean_squared_error(y_test, y_pred_test)

print(f"Training MSE: {mse_train:.4f}")
print(f"Test MSE: {mse_test:.4f}")

